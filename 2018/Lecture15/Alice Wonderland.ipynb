{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We read our input text from the text of Alice in Wonderland on the Project Gutenberg website\n",
    "(h t t p ://w w w . g u t e n b e r g . o r g /f i l e s /11/11- 0. t x t )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from input...\n",
      "Creating input and label text...\n",
      "Vectorizing input and label text...\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1247: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "==================================================\n",
      "Iteration #: 0\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 37us/step - loss: 2.3571\n",
      "Generating from seed: large bird\n",
      "large bird an the wast on the wast on the wast on the wast on the wast on the wast on the wast on the wast on \n",
      "==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 38us/step - loss: 2.0289\n",
      "Generating from seed: ice hersel\n",
      "ice herselle the whe dong the whe dong the whe dong the whe dong the whe dong the whe dong the whe dong the wh\n",
      "==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 6s 41us/step - loss: 1.9232\n",
      "Generating from seed:  opened hi\n",
      " opened hit hea d at in what in the whit the wist out wis the wist out wis the wist out wis the wist out wis t\n",
      "==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 36us/step - loss: 1.8421\n",
      "Generating from seed: ittle thin\n",
      "ittle thing of the thene of the thene of the thene of the thene of the thene of the thene of the thene of the \n",
      "==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 6s 41us/step - loss: 1.7756\n",
      "Generating from seed: oop! soo--\n",
      "oop! soo--out of the har so the was the was the was the was the was the was the was the was the was the was th\n",
      "==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 6s 40us/step - loss: 1.7186\n",
      "Generating from seed:  and held \n",
      " and held and the king to herself the marther she had a touter the marter was the gring to the gryphon and the\n",
      "==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 6s 41us/step - loss: 1.6721\n",
      "Generating from seed: ave lived \n",
      "ave lived that she had she had she had she had she had she had she had she had she had she had she had she had\n",
      "==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 6s 40us/step - loss: 1.6315\n",
      "Generating from seed: o you are,\n",
      "o you are, and seep to the said to the caterpelf all a little said to the caterpelf all a little said to the c\n",
      "==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 33us/step - loss: 1.5973\n",
      "Generating from seed:  jury eage\n",
      " jury eagerous said the caterpiller and at the caterpiller and at the caterpiller and at the caterpiller and a\n",
      "==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 4s 31us/step - loss: 1.5688\n",
      "Generating from seed: te much ac\n",
      "te much acking to herself, and the morse for a moured to be to make one the poor all the cours of the sack to \n",
      "==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 37us/step - loss: 1.5434\n",
      "Generating from seed: re of maki\n",
      "re of making alice said the queen said the queen said the queen said the queen said the queen said the queen s\n",
      "==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 6s 43us/step - loss: 1.5201\n",
      "Generating from seed: and if it \n",
      "and if it was a little garden as she cat ont got it was a little garden as she cat ont got it was a little gar\n",
      "==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 6s 39us/step - loss: 1.5006\n",
      "Generating from seed: ning, but \n",
      "ning, but the white rabbit and there was the one of the the said the mouse to the dormouse they was and the wa\n",
      "==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 6s 39us/step - loss: 1.4840\n",
      "Generating from seed: ould not j\n",
      "ould not just be the was a little she had no mouse the caterpillar said the caterpillar said the caterpillar s\n",
      "==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 37us/step - loss: 1.4689\n",
      "Generating from seed: tle bit of\n",
      "tle bit of the dormouse in the dormouse in the dormouse in the dormouse in the dormouse in the dormouse in the\n",
      "==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 34us/step - loss: 1.4542\n",
      "Generating from seed: uch pepper\n",
      "uch pepperself the door the mock turtle seress and make out of the said the king so make out of the said the k\n",
      "==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 37us/step - loss: 1.4410\n",
      "Generating from seed: said alice\n",
      "said alice, `i don't get in the dormouse the dormouse the dormouse the dormouse the dormouse the dormouse the \n",
      "==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 6s 40us/step - loss: 1.4294\n",
      "Generating from seed: i said \"wh\n",
      "i said \"whin she was not in the door was a little begly at the door was a little begly at the door was a littl\n",
      "==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 36us/step - loss: 1.4194\n",
      "Generating from seed: y, and she\n",
      "y, and she to herself, and the botter the come thing to herself, and the botter the come thing to herself, and\n",
      "==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 6s 39us/step - loss: 1.4081\n",
      "Generating from seed: back, and \n",
      "back, and all the thing to her and the morse a down and the morse a down and the morse a down and the morse a \n",
      "==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 36us/step - loss: 1.3992\n",
      "Generating from seed: swer.  `th\n",
      "swer.  `they was and the way so many like any manted to be to see it was no mouse to herself had been some of \n",
      "==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 36us/step - loss: 1.3904\n",
      "Generating from seed: lf with on\n",
      "lf with one of them, and the rabbit as she was some of the rabbit as she was some of the rabbit as she was som\n",
      "==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 35us/step - loss: 1.3830\n",
      "Generating from seed: ned):-- `w\n",
      "ned):-- `we they was a little she had got in the dormouse to the mock turtle she had got in the dormouse to th\n",
      "==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 33us/step - loss: 1.3748\n",
      "Generating from seed: at?' she t\n",
      "at?' she thought alice as it was a little she had not a sert one she was a little she had not a sert one she w\n",
      "==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      "143504/143504 [==============================] - 5s 31us/step - loss: 1.3669\n",
      "Generating from seed: ow i can d\n",
      "ow i can do sone, who was the patter.  she was net me a rumpered it would not get in the poor as the party rep\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Adapted from lstm_text_generation.py in keras/examples\n",
    "from __future__ import print_function\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "INPUT_FILE = \"alice_in_wonderland.txt\"\n",
    "\n",
    "# extract the input as a stream of characters\n",
    "print(\"Extracting text from input...\")\n",
    "fin = open(INPUT_FILE, 'rb')\n",
    "lines = []\n",
    "for line in fin:\n",
    "    line = line.strip().lower()\n",
    "    line = line.decode(\"ascii\", \"ignore\")\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "fin.close()\n",
    "text = \" \".join(lines)\n",
    "\n",
    "# creating lookup tables\n",
    "# Here chars is the number of features in our character \"vocabulary\"\n",
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "char2index = dict((c, i) for i, c in enumerate(chars))\n",
    "index2char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# create inputs and labels from the text. We do this by stepping\n",
    "# through the text ${step} character at a time, and extracting a \n",
    "# sequence of size ${seqlen} and the next output char. For example,\n",
    "# assuming an input text \"The sky was falling\", we would get the \n",
    "# following sequence of input_chars and label_chars (first 5 only)\n",
    "#   The sky wa -> s\n",
    "#   he sky was ->  \n",
    "#   e sky was  -> f\n",
    "#    sky was f -> a\n",
    "#   sky was fa -> l\n",
    "print(\"Creating input and label text...\")\n",
    "SEQLEN = 10\n",
    "STEP = 1\n",
    "\n",
    "input_chars = []\n",
    "label_chars = []\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i:i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])\n",
    "\n",
    "# vectorize the input and label chars\n",
    "# Each row of the input is represented by seqlen characters, each \n",
    "# represented as a 1-hot encoding of size len(char). There are \n",
    "# len(input_chars) such rows, so shape(X) is (len(input_chars),\n",
    "# seqlen, nb_chars).\n",
    "# Each row of output is a single character, also represented as a\n",
    "# dense encoding of size len(char). Hence shape(y) is (len(input_chars),\n",
    "# nb_chars).\n",
    "print(\"Vectorizing input and label text...\")\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1\n",
    "\n",
    "# Build the model. We use a single RNN with a fully connected layer\n",
    "# to compute the most likely predicted output char\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "NUM_ITERATIONS = 25\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,\n",
    "                    input_shape=(SEQLEN, nb_chars),\n",
    "                    unroll=True))\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "\n",
    "# We train the model in batches and test output generated at each step\n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "    \n",
    "    # testing model\n",
    "    # randomly choose a row from input_chars, then use it to \n",
    "    # generate text from model for next 100 chars\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "    print(\"Generating from seed: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for i, ch in enumerate(test_chars):\n",
    "            Xtest[0, i, char2index[ch]] = 1\n",
    "        pred = model.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2char[np.argmax(pred)]\n",
    "        print(ypred, end=\"\")\n",
    "        # move forward with test_chars + ypred\n",
    "        test_chars = test_chars[1:] + ypred\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
